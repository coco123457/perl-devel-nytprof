# vim: ts=2 sw=2 sts=0 noexpandtab:
# $Id$

HACKING Devel::NYTProf
======================

The New York Times and I encourage hacking Devel::NYTProf!

OBTAINING THE CURRENT RELEASE
-----------------------------
The current offial release can be obtained from CPAN
http://search.cpan.org/dist/Devel-NYTProf/

OBTAINING THE LATEST DEVELOPMENT CODE
-------------------------------------
You can grab the head of the latest trunk code from the Google Code repository, see
http://code.google.com/p/perl-devel-nytprof/source/checkout

CONTRIBUTING
------------
Please work with the latest code from the repository - see above.

Small patches can be uploaded via the issue tracker at
http://code.google.com/p/perl-devel-nytprof/issues/list

For larger changes please talk to us first via the mailing list at
http://code.google.com/p/perl-devel-nytprof/source/checkout

When developing, please ensure that no new compiler warnings are output.

TESTING
-------
You MUST write test cases for you changes. All tests that are dropped into the
"t" folder and added to MANIFEST will be executed.  The testing system is
customized for this module because profilers are not that easy to test.
The system still uses Test::Harness and Test::More, so it should behave just
like any other perl modules 'make test'.

Writing tests is easy!

1) Design a perl script that will trigger the new behavior/feature that you
   want to test. Name the file 't/test##-description.p'

2) Create an empty 'reference' file for the test.
   Name the file 't/test##-description.rdt'
   When the test is run you'll get an error and a diff and you'll
   find a t/test##-description.rdt.new file waiting for you.
   If, and only if, the contents of that file are correct, then rename
   it to t/test##-description.rdt and you're done!
   Of course working out if the contents are correct can be
   non-trivial, but at least you don't have to write the file :)

3) Create a corresponding CSV output file if appropriate.
   You can use the same trick of creating an empty file, but this
   time with a .x suffix: t/test##-description.x
	 You still need to verify the .x.new file of course!

Note:  While writing a test, it is helpful to be able to run it directly, 
			without the test harness.  This allows you to view more output stdout and 
			stderr.  Fortunately, its easy to do:

			PERL5LIB=blib/lib:blib/arch perl -d:NYTProf t/test01.p

			The output will be in ./nytprof. You can then also run
			the csv manually:

			PERL5LIB=blib/lib:blib/arch perl bin/nytprofcsv

			The final file will be in ./profiler/test01.p.csv

If youve changed any internals of the profiler then don't forget to also test
'use_db_sub' mode, like this:

	NYTPROF_TEST=use_db_sub=1 make test

Remember, testing is VERY VERY important!  Within a day or two of releasing
code, the CPAN testers will test the release on pretty much every major platform
you can think of.  A failed test report is much easier to fix than a runtime
error like "bash: segmentation fault: core dumped"

GENERATING DISTRIBUTIONS
------------------------
Releases are generated with 'make metafile', and then fed through tar+gz.
You shouldn't ever check-in the distribution directory, any temporary files
(including Makefile.old) or change the $VERSION numbers. We'll do this for you.

RESOURCES
---------
Google Code:
http://code.google.com/p/perl-devel-nytprof/

Google Devel Group (must subscribe here):
http://groups.google.com/group/develnytprof-dev

NYTimes Open Code Blog:
http://open.nytimes.com/

TODO (unsorted)
----

Fix Reader
- not document methods with a leading underscore
- to have consistent_naming_style notMixedCamelCase (fixed?)
- to be fully OO (ie not document non-OO interfaces)
- to be subclassable
- to provide a subclass to manage generating CSV
- to provide a subclass to manage generating HTML
Then rework bin/ntyprof* to use the new subclasses
Ideally end up with a single nytprof command.

Add (very) basic nytprofhtml test (ie it runs and produces output)

Rework option parsing so options can be implemented in perl, accessed from
perl, and stored in data file.

Write tests for new functionality.

Write up change notes

Write, clean-up documentation

Currently the cost of calling the sub goes to the caller (good)
but the cost of copying the result goes to the method (poor).
Overriding pp_leavesub may allow more accurate measurements by avoiding return
value processing overheads accumulating on last statement in sub.

Similarly, the cost of retesting the loop condition is accounted
for by the last statement executed each time round the loop.
Overriding relevant ops may enable better accounting.

Add way for program being profiled to switch output to a new profile file.
Perhaps via enable_profile($optional_new_filename)
See http://search.cpan.org/dist/Devel-Profile/ for use case.

Add @INC to data file so reports can be made more readable by removing
(possibly very long) library paths where appropriate.

Add size and mtime of fid to data file.

Intercept all opcodes that may fork and run perl code in the child
	ie fork, open, entersub (ie xs), others?
	and fflush before executing the op (so fpurge isn't strictly required)
  and reinit_if_forked() afterwards
	add option to force reinit_if_forked check per stmt just-in-case

Add way to merge profile data. Merging could be done in perl.

Add constants to Data.pm for the array indexes
0=time_spent
1=exe_count
2=eval_line_data

Add method to remove data (like sub_fid_lines) relating to specific files
so that the .rdt tests aren't affected by variations between versions of library modules.

Support profiling programs which use threads:
	- move all relevant globals into a structure
	- add lock around output to file

Add functions to read & write strings to the profile data file that uses an
integer length prefix.  Replace all current newline-terminated strings with the
new code, so we're safe from embedded newlines and can also store multi-line strings.

Support optionally generating a compressed data file (using popen("zip -c > $file"))

Support optionally saving eval strings (from @{"_<$filename"}, see perldoc perldebguts)
Should always save the first eval string at each distinct eval (fid:line)
and require an option to save them all (which could make the data file very large).

Add % of total time to index page
Remove bottom stats.

Use clock_gettime(CLOCK_MONOTONIC) if available, else clock_gettime(CLOCK_REALTIME).
Those calls are cheaper than gettimeofday and can give nanosecond resolution.

nytprofhtml: output list of subs as a table and include timings aggregated from
the line ranges. (Won't be accurate for overlapping subs, such as anonymous
subs, but those can be detetected and a note added.)

The whole reporting framework needs a rewrite to use a single 'thin' command
line and classes for the Model (lines, files, subs), View (html, csv etc),
and Controller (composing views to form reports).

Add timing to sub calls by using save stack to trigger end of timing measurement?

Add resolution of __ANON__ sub names (eg imported 'constants') where possible.

Trim leading @INC portion from filename in __ANON__[/very/long/path/...]
in report output. (Keep full path in link/tooltip/title as it may be ambiguous when shortened).

Explain what's shown in html reports, ie say it's elapsed realtime.

Use 'Statements' or 'Stmts' instead of Calls in reports.

Only warn "No file line range data for sub' once per sub.
Add hint that it may be XS.
Could also note fact that it is XS in pp_entersub_profiler

Currently the line of only last BEGIN (or 'use') in the file are recorded.
Rename Foo::BEGIN subs to Foo::BEGIN[file:line]
(which matches the style used for Foo::__AUTO__[file:line])
Probably need to record or output the line range when the BEGIN 'sub' is entered.

Record $AUTOLOAD when AUTOLOAD() called
Perhaps as ...::AUTOLOAD[$AUTOLOAD]

Refactor this HACKING file!

Add docs for new options

Add docs for use_db_sub and explain pros & cons. Especially that opcode
redirection can't profile code that was loaded before NYTProf because
it only affects code that is *compiled* after it takes effect.
(Unless we want to traverse the existing compiled code and edit the ops in place :-)

Would be good if DB::DB sub wasn't defined when use_db_sub is false
so the profiler could be used to profile debuggers etc.

Add file format backwards compatibility tests.

Add tests for evals in regex: s/.../ ...perl code... /e
